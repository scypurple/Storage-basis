# **第13章 大数据**











## 什么是“数据湖”

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-05-19*

   最近围绕“数据湖”这个概念的炒作不断升温，特别是在Pivotal和EMC分别发布了有关数据湖解决方案的案例之后。本文就来带大家了解一下到底什么是数据湖。

 

**什么是数据湖:**

 

   截至目前Pivotal和EMC对数据湖这一概念的推广是最用力的，但这一概念最早应该是在2011年由CITO Research网站的CTO和作家Dan Woods提出。简单来说，数据湖是一个信息系统，并且符合下面两个特征：

1. 一个可以存储大数据的并行系统
2. 可以在不需要另外移动数据的情况下进行数据计算



   目前，Hadoop是最常用的部署数据湖的技术，所以很多人会觉得数据湖就是Hadoop集群。但未来总会有新的技术出现，因此我们要区分出Hadoop和数据湖的不同点。数据湖是一个概念，而Hadoop是用于实现这个概念的技术。

 

**数据湖应用：**

 

   Pivotal大数据套件是目前较为完整的数据湖解决方案。它以基于Hadoop的Pivotal HD架构为基础，整合了内存数据库网格软件GemFire XD，具有实时处理HDFS中数据的能力。



   GemFire通过平台虚拟化技术，将若干x86服务器的内存集中起来，组成最高可达数十TB的内存资源池，将全部数据加载到内存中，进行内存计算。计算过程本身不需要读写磁盘，只是定期将数据同步或异步方式写到磁盘。GemFire在分布式集群中保存了多份数据，任何一台机器故障，其它机器上还有备份数据，不用担心数据丢失，而且有磁盘数据作为备份。

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIWRyj9aQ2xzibhDV2KkPMZPl4k2J9Lmzt5svT9rOnbhh9yjDsbS5kNiaibUjaMkWicBmZXibxJ6HmzHOsw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



   在方案中，位于数据湖最底层的则是EMC Isilon Scale-Out存储。Isilon负责承载命名节点跟踪服务器和HDFS数据节点。一个完整的数据湖架构实例如下：

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIWRyj9aQ2xzibhDV2KkPMZPlOcAhJibwRzR4swVXcfibMNelWoGvCWX59xusibhv3SeKuErtOib34SUeCQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



   虚拟环境结构如下：

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIWRyj9aQ2xzibhDV2KkPMZPlk0LrKJPibtFPI3xFRsRhcGc8m8oY3Qw8GO7lfJAjOYmAACcElWsr4Yw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

**机会与风险：**

 

   虽然数据湖这一概念很火，很多厂商都生成数据湖是抓住大数据机遇的一个重要组成部分，但是厂商们却对是什么构成了数据湖、或者如何从中获得价值没有达成一致。数据湖的重点是保存不同的数据，却忽略了如何使用数据以及为什么要使用数据、监管数据、定义数据和确保数据安全。数据湖概念希望解决一老一新两个问题。老问题是，信息孤岛。你可以将不同来源都集中到一个未经管理的数据湖中，而不是保持数十种独立管理的数据集合。从理论上讲，整合的结果是加强信息利用和共享，同时降低服务器和许可成本。



   而新问题，则是涉及到大数据分析。大数据项目要求大量的各种信息。这些信息如此不同，以至于我们不知道这些信息究竟是什么，以及什么时候收到的，就把它归类到某种类似数据仓库的结构化数据，或者关系型数据库管理系统以便未来使用。



   因此，数据湖存在着重大风险。最重要的一点，是无法决定数据质量或者利用其他已经发现价值的分析师或者用户在使用湖中相同数据中的经验发现。从定义上看，数据湖可以接收任何数据，不受监督或管理。没有描述性的元数据，和维护它的机制，数据湖会转变成数据沼泽。如果没有元数据，所有对数据的后续使用都意味着从零开始对数据进行分析。



   另外一个风险是安全性和访问控制。数据可以在不受内容监管的情况下被放到数据湖中。很多数据湖中数据的使用意味着其隐私和法规要求很可能使其暴露于风险之下。数据湖核心技术的安全能力仍然处于早期萌芽阶段。如果交给非IT人员的话，这些问题将不会得到解决。



   最后，性能方面的因素也不容忽视。当然相对而言解决性能问题的方法还是比较多的。























## “大数据”概念解析

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-05-20*

本文作为“存储基础知识”系列文章之一，将介绍大数据的概念和组成部分。

 

大数据是一个新提出的且在不断演化的概念，是指数据量超过了常规软件工具在可接受的时间内的抓取、存储、管理和处理能力。它即包括结构化数据，也包括非结构化数据。其数据的来源多种多样，可以来自商务应用处理、网页、视频、图像和社交媒体等。这些数据集通常需要实时地抓取和更新，以用于分析、预测性建模和决策等用途。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIXClPplbwicH0ksJVHqzzEkuB8gLzLGQbhT5y7YTparI2fAKutzGjD4D2hb2pDXIBgQvCIErwa6wqQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

 

从大数据中吸取价值存在很大的机遇。大数据的生态系统（如下图所示）由以下元素组成：

 

1. 从多个位置收集数据，并从收集的数据中生成数据（元数据）的设备。
2. 数据收集器，收集来自设备和用户的数据。
3. 数据聚合工具，从收集的数据中吸取有意义的信息。
4. 数据用户和买家，是指数据价值链中从他人收集或聚合的数据中收益的人群。

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIXClPplbwicH0ksJVHqzzEku2oWvllmic47eJLiaxUCVdbQRtYcpVlMNhViad4kl89RicHSuXAhr806X1g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

大数据的数据量、多样性、变化范围和复杂性超出了传统的IT设备和数据处理工具及方法的处理能力。对大数据进行实时分析需要新的方法、架构和工具，以提供高性能、大规模并行处理（MPP）数据平台和对数据集的复杂分析。

 

数据科学是一门新兴的学科，商业组织可以利用这门学科从大数据中获取商业价值。数据科学是多门学科（统计学、数学、数据可视化和计算机科学）的综合。数据科学家的职责是设计各种高级算法对海量数据进行分析，以寻找新的价值点，为更多的决策提供数据支持。



很多领域和市场已经开始利用数据科学，从大数据的分析中获益。其中包括医学与科学研究、医疗医护、公共管理、欺诈检测、社交媒体、银行、保险公司，以及其他以数据为中心的实体。



















## 大数据如何创造价值

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-05-21*

   到2020年，电子存储数据的数量将达到35万亿GB，这是现今的四十多倍。根据EMC赞助的IDC数字世界研究，到上年年底已达到120万PB (1.2 ZB)。这些数据填充的DVD堆叠起来足以从地球往返月球一趟，单程大约24万英里。这在一些忧心忡忡的人看来，不啻于数据存储末日的预兆。对于机会者而言，这是信息金矿，其财富挖掘将随着技术的进步而日益轻松。那大数据如何才能真正创造价值呢？

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIXClPplbwicH0ksJVHqzzEkuwlDELLE69gEdpC2J7icRayIkJaxUbf2jBWVnkN8ZMLciaqibgMpM39bxw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



   数据量在二十一世纪早期直线上升，当时存储和CPU技术在无数TB的大数据面前显得不堪一击，IT甚至面临了可扩展性危机。现在，我们再次逃离被摩尔定律打败的虎口。存储和CPU不仅提高了容量、速度和智能；它们的价格也降低了。企业经历了从无法支付或管理大数据到为收集和分析大数据而分配预算的转变。过去的技术问题现在成为了巨大商机。数字数据无所不在；它存在于每个行业、每种经济、每个组织 — 使得大数据与各行各业的领导者息息相关。



   利用这些数ZB的结构化和非结构化数据（来自运营系统、手机、Twitter、Facebook和其他现代来源）将有助于降低成本、改善客户关系、开发新产品、加速和同步交付、提出和回答更深入的问题以及增强和简化决策制定。大数据就是让所有此类信息工作。访问这世上如此多ZB 的数据对您的业务没有任何意义，除非您开始应用新一代分析工具和方法获得有助于您推动组织前进的洞察力。



   麦肯锡全球研究所（McKinsey Global Institute）建议，如果美国医疗保健行业能够以创新和高效方式使用大数据来提高效率和改进质量，该领域的数据的潜在价值将超过3000亿美元，其中三分之二体现在可将全国医疗保健支出降低约8%。在私营部门，麦肯锡估计充分使用大数据分析的零售商具有将运营利润提高60%以上的潜能。大数据让您可以超乎目前想象地创新以解决问题，并创造出以前从未想过的产品或服务！简单的报告、电子表格，甚至相对复杂的深入查看分析，已经成为司空见惯的业务智能形式。但是，有些类型的分析无法通过业务智能产生，而这正是大数据的用武之地。

 

   大数据分析探究业务运营和客户交互的精确细节，这些细节很少进入数据仓库或标准报告，因为此类信息中有越来越多的部分是无法采用整齐的行列表格形式收入仓库或进行分析的。此外，此类数据不断移动，因此其速度让当前的RDBMS模型束手无策。在您追求预测分析、自然语言处理、机器学习或高级统计技术等时，即使想要分析和揉杂业务智能中的非结构化内容，也需要新技术和新方法来处理数据，以便获得可为组织带来价值的见解。



   通过利用大数据分析的威力，您可以发展“信息优势，且可从使用数据了解过去经验教训的响应型组织转变为使用大数据中包含的见解预测和把握将来机会的预测、主动型组织。在用于处理数据的底层技术、平台和分析功能不断革新以及用户行为变革的推动下，且随着越来越多的人过上数字生活，大数据的可能性将继续快速演变。使用大数据技术和分析将成为关键竞争指标，且可能会给行业带来新的竞争对手或竞争方式。在您随着浪潮前进时，请考虑以下事项：



1. 成功利用大数据洞察力要求在成熟技术、工作人员技能和领导力重心方面具有实际投入。

2. - 预计在未来的5-10年将增加大量新技术和新兴技术，因此不要忘记调整您的人员和流程，以便与大数据时代的新工作方式同步。
   - 组织需要将大数据集成到信息体系结构的缜密战略，以便大数据可扩展并成为经营方式的一个核心部分。务必成立一个由业务和技术领导组成的团队，重点关注大数据，并仔细考虑这些问题和计划机会。

3. 最终，为您的组织或业务拉开竞争距离的是您如何通过分析眼光利用大数据。

4. - 审查和更新数据战略和策略。最重要的是，开始将数据视为创造新经济价值的引擎。领导们应该评估并填补当前 IT 职能和数据战略之间的任何差距，并想清楚为抓住与组织相关的大数据机会而必需做的事情。



   将大数据技术归入超级计算环境后，企业群体都可利用这一技术，而随着这一技术的利用，许多行业经营业务的方式将发生变化，我们生活的世界也会发生变化。



















## 当存储遇上大数据

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-05-24*

大数据给存储管理带来了一些挑战。然而，将大数据和Hadoop在存储环境中有效集成能够解决这些问题。

 

现如今，大数据似乎无处不在，但“大”只是相对的，重点应当聚焦在“数据”部分。大数据分析需要海量数据。因此，数据的存储和保护，并维持其可用性与可访问性，需要繁重的数据管理。许多大数据平台如Hadoop，以及非关系型数据库采用的是非共享型结构。但是，这类结构可能给存储管理带来一些问题。

 

大多数存储专家花了数年，甚至数十年，将数据整合到尽可能少的存储中。他们告知终端用户将数据存放于一台服务器上，以方便数据备份和管理。为了在重型多租户共享存储系统中将性能和可靠性最大化，采用经过优化的RAID系统。

 

但是Hadoop的到来打破了所有这些规则。Hadoop最佳运行于分布式环境并且结合本地服务器。这种存储模式不符合企业可靠性，可用性和可服务性的概念。事实上，大多数情况下，可认为该体系结构的分布式非共享特质并不符合企业特征。

 

 

**大数据带来的大问题:**

 

由于很多企业都开始涉足大数据平台，因此，按照平台厂商所建议的技术架构搭建专门针对大数据项目的平台环境是合理的做法。因此，在Hadoop环境下，调用了很多分布式节点，每一个节点都具有本地存储，而所有这些都位于一个公共的LAN中。这种布局的好处在于：它将Hadoop的sandbox与生产环境隔离开来。

 

但是，这种设计在某些关键领域无疑谈不上最佳：

- 数据变得重复
- 提取，转换和加载进程导致大量数据迁移

 

这可能带来一些存储管理者不想看到的后果：记录，文件或对象将变得非常庞大，传统存储系统没有充足的吞吐量来及时交付数据，没有足够的带宽来处理业务，也没有足够的容量来存放大量数据。这就会导致存储的铺开蔓延——数十上百个存储仓，数十上百个管理点，往往伴随着空间，电力的浪费。数据存储系统可能到达性能瓶颈无法按时完成操作；传统存储不具备处理I/O请求的能力。这往往导致用户在磁盘上存放更少的数据并且对磁盘“short stroke（对磁盘进行格式化以使数据仅写入外部扇区的行为）”。实际上造成每GB占用的磁盘数量增长而更多磁盘需要应付I/O。也有可能因性能瓶颈造成部署大量存储而又无法充分利用其容量。

 

如前文所述，存储管理员花费大量时间将存储数据标准化。为了使标准化成为可能，衍生了诸如数据消重等专门化产品。但是，如果企业仅仅为了大数据而创造专门的环境，那么数据消重和数据容量优化带来的许多好处也就失去了意义。

 

此外，除了管理重复数据，如何管理从生产环境和数据仓储环境迁移至大数据环境中的数据也是极具挑战性的。根据大数据环境的设计，数据可能先复制然后存放于大数据环境中，或者在很多情况下，每一次大数据处理都需要将数据输入一次。这种输入被称为ETL（extract, transform, load）。数据从源设备中提炼（例如，从数据仓储），之后被转化（成为与大数据环境兼容的形式），并且加载到目标环境中。ETL进程会对存储网络构成相当大的压力。

 

最后，鉴于大数据基础架构不同于企业其他结构，传统数据管理应用可能无法管理，优化以及维护大数据架构。

 

**存储理想状态并非不可实现：**

 

理想情况下，数据从OLTP，OLAP到大数据所有平台都应当经过标准化。这一概念通常被称为“事实来源的单一性”。设计针对性能，容量利用率，可用性和可管理性做了优化。

 

要达到这一存储理想状态，存储管理者需要直面大数据分析进入数据中心的必然性。存储管理员应当尝试铺设引入新的设计架构。实现这一目标的最佳方式就是提出作为访问数据新方式的协议，例如Hadoop分布式文件系统（HDFS）。Hadoop对于海量数据的处理包括两部分：MapReduce和HDFS。简单来说，MapReduce负责计算任务管理部分，而HDFS自动管理数据位于计算集群的存放位置。当一个计算任务被发起，MapReduce将它划分成能够并行运行的子任务，它要求HDFS查看每一个子任务所需数据位于何处，之后将计算任务发送到数据存放处所在的计算节点。本质上，是将计算任务发送给数据。子任务的结果发回给MapReduce master，由它来收集并发布最终结果。

 

与传统架构相比，这种差异可以用一个简单的比喻来概括：假设一家杂货店里有20个人，要经由同一个收银台来结算。如果每个人购买价值200美元的杂货，结算花费2分钟，那么40分钟内杂货店可收入4000美元。Hadoop版本的场景是：由十个低成本的兼职高中生组成十条收银线，每个人要多花费50%的结算时间（3分钟），一共花费6分钟完成20个人的结算但还是可以收入4000美元。

 

这种方式并不是面向企业的，而是面向大数据的。目前，只有少量存储系统能够提供HDFS作为接口（最为显著的可能是EMC Isilon存储阵列）。另一备选项则是选择一种大型数据分布（如Hadoop）以支持传统企业存储协议，如NFS。

 

最后，存储管理员需要将当前的存储系统和存储架构发展成为对象可寻址的存储架构（即基于对象的存储）。很多存储管理者尚未意识到的一点是，象Hadoop这样的解决方案并不是单一的软件，而是一个框架结构。框架中的存储相关部分就是HDFS。作为一种文件系统，HDFS提供了一层数据管理层。事实上，HDFS能够利用其特质来创建一种完全对象可寻址的环境。越来越多的独立软件厂商为HDFS提供支持，以使传统网络存储能够与HDFS相集成。未来，企业可能会放弃某些他们所熟悉的可移植文件系统，取而代之的是基于HDFS的存储设备。

 

例如，EMC Isilon存储系统，是一种横向扩展式（scale-out）存储架构。横向扩展式存储架构能够以充足的带宽来处理大容量文件。传统上，纵向扩展式（scale-up）隐含一种终极的限制，而横向扩展式对于容量与处理能力的扩展限制要小多了。Isilon能够使用既有的存储管理以及数据中心管理方案（例如VMware vCenter）。Isilon的横向扩展能力，以及对HDFS的支持使得性能得以通过I/O分布于多个控制器节点来实现优化。但最关键的是，它允许数据“待在原地”，而无需为了大数据分析处理而移动数据。

 

源于终端设备（移动设备，台式机或笔记本）的数据可能经由SMB接口被写入。这些数据经过收集，由NFS之上一些关键任务型应用加以采用，之后同样的数据（通过HDFS接口）成为Hadoop框架的一部分，而无需经过提取，转化或从一个存储系统加载到另一个。

 

这种方法对于企业非常具有吸引力：

- 数据能够根据企业策略来压缩或消重
- 数据能够如传统存储系统一样备份和管理
- 能够准确对数据源进行审核，从而提升可管理性

 

对象可寻址的存储概念与文件同步和共享环境的基本设立理念相同，如Box或Dropbox。但是，不同于终端设备使用数据，而是由关键任务型应用来对数据进行处理。数据的可移植性将数据应用几率以及企业价值衍生提升到一个新的高度。这种对象方式也减轻了LAN和SAN的压力，因为实际上排除了ETL。

 

一些厂商已经将专为Hadoop设计的应用进行组合，如Pivotal的Data Computing Appliance（DCA）。通过将服务器，网络，存储以及Hadoop紧密集成以优化部署和维护。Pivotal的DCA所有存储是系统节点本地所有的，但并没有native HDFS接口。EMC Isilon是具有native HDFS集成的存储系统。

 

**关于大数据的大实话：**

 

大数据和Hadoop是一个重新审视公司存储架构的推动力。存储管理员需要考虑如何改进现有的架构使之更加灵活，动态可变及多用户友好。

 

下一代高度虚拟化数据中心将会以数据为中心，而不是以计算为中心。存储管理员的职责是创建在应用之间最小化（甚至优化为无需）数据移动的架构。同样需要纳入考虑的是这一进化对于备份和灾难恢复策略的影响。

 

对于存储管理者来说最重要的可能在于，这是一场进化，而不是一次变革。也就是说，那些尽快发展的企业将会取得先发优势；如果这部分企业的数据用户能够利用这一优势，他们同样能够为他们的企业赢得竞争优势。

 

关于大数据，还有一件事是可以肯定的：你不去做，你的竞争对手就会去做。这种进化意味着将IT部门从一个成本中心改变为动态信息服务提供者。



















## EMC存储上的大数据系列文章

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-24*

企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。原有的存储经扩展后缀让能勉强跟上计算容量增长的步伐，但是用来分析该大数据以得出宝贵见解的工具却落入后了。



Hadoop是一款经专门设计的创新性开源大数据分析引擎，旨在最大程度地缩短从企业的数据集到处宝贵见解的时间。



这里将为您带来15篇EMC存储上的大数据系列文章。



[EMC存储上的大数据 – Hadoop软件概述](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771117&idx=2&sn=2c8fc6c64da605d6cd4cf97102e0481f&scene=21#wechat_redirect)

[EMC存储上的大数据 – Hadoop生态系统与体系结构](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771116&idx=3&sn=5a018088d98617658604720fe2810ed6&scene=21#wechat_redirect)

[EMC存储上的大数据 – 利用大数据增强业务可见性](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771124&idx=1&sn=61595d5fd1cfcf8acaca2caf5d25eab7&scene=21#wechat_redirect)

[EMC存储上的大数据 – HDFS on Isilon（一）](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771130&idx=3&sn=80d958499f589084d8a6b39bd7ef1448&scene=21#wechat_redirect)

[EMC存储上的大数据 – HDFS on Isilon（二）](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771141&idx=2&sn=b8ef71e2b08d941c964b7c73fe014542&scene=21#wechat_redirect)

[EMC存储上的大数据 – HDFS on Isilon（三）](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771142&idx=2&sn=d3564d731c1da167a7a9ecf5d9c729f5&scene=21#wechat_redirect)

[EMC存储上的大数据 – HDFS存储可靠性](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771147&idx=3&sn=9cb9386e2154cfd46d532e60a657d6f4&scene=21#wechat_redirect)

[EMC存储上的大数据 – 基础架构与数据分析](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771158&idx=2&sn=68fdf8f9162b8836df6e4347af300912&scene=21#wechat_redirect)

[EMC存储上的大数据 – 敏捷分析与可行性洞察](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771159&idx=2&sn=c465f2f9cdbe00a9b42dfe1f8a7c0f22&scene=21#wechat_redirect)

[EMC存储上的大数据 – 大数据分析实施路线](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771165&idx=2&sn=c96df12a1adc76c2d1df5b200b4b3f8d&scene=21#wechat_redirect)

[EMC存储上的大数据 – 软件定义存储模型](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771172&idx=1&sn=9c46728184be92aeefa9058d427893f6&scene=21#wechat_redirect)

[EMC存储上的大数据 – 软件定义存储数据服务与HDFS](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771180&idx=2&sn=b4fffac1cc1d7d1c28fc36fda9afae31&scene=21#wechat_redirect)

[EMC存储上的大数据 – 面对大数据安全挑战](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771188&idx=2&sn=6336af9bceb7ab4be8cf04ed6f512962&scene=21#wechat_redirect)

[EMC存储上的大数据 – 数据推动高效安全](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771193&idx=2&sn=242c044eb6636a45ab67a5ee96cd4758&scene=21#wechat_redirect)

[EMC存储上的大数据 – 安全分析阶段方法](http://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771198&idx=2&sn=64aba2c95c5bd77ee193f7f8e37431ce&scene=21#wechat_redirect)















## EMC存储上的大数据 – Hadoop软件概述

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-01*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。原有的存储经扩展后缀让能勉强跟上计算容量增长的步伐，但是用来分析该大数据以得出宝贵见解的工具却落入后了。Hadoop是一款经专门设计的创新性开源大数据分析引擎，旨在最大程度地缩短从企业的数据集到处宝贵见解的时间。本文为系列的第一篇，介绍了Hadoop软件的核心组件MapReduce和HDFS。

 

   Hadoop是一款经专门设计的创新性开源大数据分析引擎，旨在最大程度地缩短从企业的数据集到处宝贵见解的时间。他包括以下主要组件：



- MapReduce
- Hadoop分布式文件系统（HDFS）
- HIVE
- PIG
- HBASE
- ZOOKEEPER





   **MapReduce：**



   MapReduce是一种分布式任务处理框架，可在多个节点上并行运行作业，以更快地从大型数据集得出结果。Hadoop MapReduce是一个软件框架，可用于轻松编写大型商用计算节点集群上并行处理大量数据的应用程序。早期MapReduce被Google作为一种计算模式推出，而Hadoop被Yahoo作为这种模式的实施编写并献给开放源代码。



MapReduce框架包括下列组件：



- JobTracker：每个节点集群配备单一主JobTracker，用于计划、监视和管理作业及其组件任务。
- TaskTracker：每个集群节点配备一个从属TaskTracker，用于按照JobTracker的指令执行作业的任务组件。



   MapReduce作业（查询）由多个映射任务组成，这些任务跨集群分布，并且以完全并行的方式进行处理。框架对映射的输出进行排序，这些输出随后被用作缩减任务的输入。通常使用HDFS跨节点就能存储作业的输入和输出。框架负责计划任务、监视任务并管理失败任务的重新执行。在Hadoop集群中，MapReduce计算节点和HDFS存储层通常驻留在同一组节点上。该配置使框架能够有效地在已经存在数据的节点上计划任务，以便避免与在节点集群内移动数据相关的网络瓶颈。这正是计算层通过与HDFS层中的数据位置对齐来有效推导关键见解的方式。Hadoop完全用Java编写，但MapReduce应用程序不必如此。MapReduce应用程序可以利用Hadoop流接口来指定任何可执行文件作为特定作业的映射程序或缩减程序。





   **Hadoop分布式文件系统（HDFS）**



   HDFS是一种分布式文件系统，Hadoop集群借此来存储所有需要分析的输入数据以及由MapReduce作业生成的任何输出结果。HDFS是一种基于数据块的文件系统，它跨越集群中的多个节点，并且使用用户数据可以存储在文件中。它提供了传统的分层文件组织，以便用户或应用程序可以操作（创建、重命名、移动或删除）文件和目录。它还提供了一个流接口，借助于该接口，可使用MapReduce框架运行所选的任何应用程序。HDFS不支持设置硬链接或软链接，因此用户无法寻址到特定数据块或者覆盖文件。HDFS要求进行编程访问，因此用户无法作为文件系统装载。所有HDFS通讯都根据TCP/IP协议分层。



HDFS的关键组件有：



- NameNode：单一主元数据服务器，其中包含每个文件、文件位置以及这些文件及其所在的DataNode内的所有数据块的内存映射。
- DataNode：每个集群节点均有一个从属DataNode，它为读/写请求提供服务以及按照NameNode的指令执行数据块创建、删除和复制。



   HDFS是所有数据在MapReduce作业可依其运行之前所驻留的存储层。HDFS使用数据块镜像，让数据分布于受保护的Hadoop集群以及跨多个计算节点的数据位置之中。默认数据块大小是64MB，默认复制因子是3x。



   Hadoop构建在横向扩展的原则之上，它借助于在一个商业硬件集群上运行的智能软件，以一种快速、经济且高效的粉丝推导出宝贵见解。得益于这种分布式并行任务处理，因此，可以让Hadoop可在分析大数据领域大展身手。





   **HIVE**

 

   HIVE是Hadoop的一个数据仓库系统，允许轻松地执行数据摘要，即兴查询和分析Hadoop兼容文件系统中的存储的大型数据集。SQL风格的界面为用户提供基于行的存储功能。此功能能与压缩功能一起，提高了存储数据的压缩比率。

 



   **PIG**

 

   Pig是一种编程语言，借助Hadoop MapReduce平台处理大型半结构化数据集。它可以为开发人员提供一种代替Java的编程语言。从而让他们更轻松地编写MapReduce作业。





   **HBASE**

 

   HBASE是一个有版本控制，以列为想到的分布式存储平台，可为用户应用程序提供对大数据的随机实时读/写访问。





   **ZOOKEEPER**



   Zookeeper是一个高可用性的系统，用于协调分布式进程。分布式应用程序使用Zookeeper来存储和传递对关键配置信息的更新。

 







## EMC存储上的大数据 – Hadoop生态系统与体系结构

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-06-30*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。原有的存储经扩展后缀让能勉强跟上计算容量增长的步伐，但是用来分析该大数据以得出宝贵见解的工具却落入后了。Hadoop是一款经专门设计的创新性开源大数据分析引擎，旨在最大程度地缩短从企业的数据集到处宝贵见解的时间。

  

   本文为系列的第二篇，介绍Hadoop软件生态系统与体系结构。

 

**Hadoop版本：**



   Hadoop的版本由开源Apached Foundation在apache.org中维护。其他所有版本都是扩展Apache Hadoop或根据其构建的派生版本。下面是目前提供的常见Hadoop版本列表：

- Apache Hadoop
- Cloudera CDH3
- Greenplum HD
- Horonworks数据平台

  

   以上列表并未详尽列出目前提供的所有Hadoop版本，而只是简单列出了流行的选择。



 

**Hadoop生态系统：**



   以下是客户为使用Hadoop分析数据而运行的软件堆栈。生态系统组件是Hadoop堆栈之上的附加组件，面向分析工作流提供附加功能和优势。该领域中一些流行的选择包括：

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIVngtxDdsFIF51zZqkykPOQS7LibibaQR0RZYLSx8A8fVOkc7O12ibtOuY42TIyMP3nd3UOOyx8bLAVA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

- Hive：一个类似于SQL的查询接口，适用于HDFS中存储的数据。
- HBase：一个面向随机读/写列的高性能结构化存储系统，位于HDFS之上。
- Pig：高级数据流语言和执行框架，适合于并行计算
- Manhout：使用Hadoop的可扩展的计算机学习算法
- R（RHIPE）：细分并重组大型复杂数据集的统计分析

  

   以上并未详尽力促所有的Hadoop生态系统组件。

 



**Hadoop体系结构：**



   下面是一个体系结构图，其中显示了在一个Hadoop计算集群上运行的所有核心Hadoop组件。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIVngtxDdsFIF51zZqkykPOQZ8BF6lBrtg0Bj7HQtGSWJGMl3rHC3voXnCUswwU79wbCur9zn6Ffrw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

该计算环境中发生的常规交互包括：

- 必须将数据接收到HDFS层内。
- 使用MapReduce对数据进行计算或分析。
- 在HDFS或其他基础架构中存储或导出结果，以适应整个Hadoop工作流。



   上述体系结构还表明NameNode是该环境中的独立组件，如果它有任何问题，则整个Hadoop环境都将变得不可用。











## EMC存储上的大数据 – 利用大数据增强业务可见性

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-04*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。



   本文为系列的第三篇，从业务角度介绍利用大数据增强业务智能，实现“高清”业务可见性。

 

   众所周知，“大数据”一词涵盖的不仅仅是结构化和基于事务的数据。它还包括视频、RFID（射频识别：radio frequency identification）、日志、社交网络对话，传感器网络、搜索引擎、环境条件、医学检查、“数据废气”（网络浏览者在互联网上留下的痕迹）等等。任何可数字化的东西都会生成有关谁在使用它、他们如何使用它、甚至他们为何使用它的数据。大数据并不总是心数据，有时也指以不同方式看待的现有数据。目前，生成的数据已超过计算机网络所能传输的数据。



   大数据方法是业务智能（BI）工具的补充，可从企业信息中开启价值。BI传统上执行结构化分析并提供观察业务绩效的后视镜，而大数据分析提供一种前瞻视野，使组织能预见未来商机并相应展开行动。



   简单的报告、电子表格、甚至相对复杂的深入查看分析，已经成为司空见惯的BI预期。但是，还有一些BI不能处理的分析类型，尤其是当数据集越来越多样化、颗粒更细、变得实时和具有迭代性时、这要求组织可在条件改变之前的特定时间快速获取深入信息。这些类型的非结构化、数量庞大、且快速变化的数据（即大数据）打破了关系数据库模型。这类数据要求采用新型技术和分析方法来提取价值。例如，当组织需要进行预测分析、自然语言处理、图像分析或高级统计方法（如离散选择建模和数学优化）、甚至当他们想要捣烂非结构化内容并连同其BI混合一同分析时，大数据方法非常重要。



   利用大数据来增强BI的公司必定能获得对其业务更为全面的认识。这就像从只具有基本网络频道的模拟信号电视过渡到具有付费有线电视频道的高清电视。组织得到的结果是对业务情况的“高清”可见性，这种可见性能得到丰富、范围广泛、更精确、更可操作的洞察力，从而帮助应对客户需求、运营风险以及绩效机会，这不仅在企业内部，还在扩展供应链上。借助大数据分析，公司不仅可以了解发生的情况以及原因，还可以领会到其他可能发生的事情。



   而在这个过程中，重新思考数据也需要审视传统的思维方式，传统的思考方式认为数据太多是件坏事，因为不断增加的数据增加了基础将爱狗成本，而管理和挖掘起来难以控制。现在，公司组建认识到多才是好，因为大数据提供了盈利，提高效率和获得竞争优势的新方式。



   全球经济各个领域的公司都开始从大数据受益。但是，有些行业利用大数据相对来说较为容易。在IT方面积极投入的领域在应对技术转变时准备得更充分。习惯以来数据获得商业情报的行业将更快适用大数据，并在将数据转化为洞察力上更老练。企业管理人员预期较早采用大数据分析的公司将包括金融服务、零售业、制造业和互联网行业。最终，大数据的优势体现在适时、深入的业务洞察力。得到这些洞察力需要时间和新的思维方式。因此，企业领导人应开始考虑其组织必须进行的基础架构、认识和文化变革。



















## EMC存储上的大数据 – HDFS on Isilon（一）

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-05*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。

  

   本文为系列的第四篇，介绍HDFS与Isilon的集成功能。

 

   HDFS中的所有通讯都根据TCP/IP协议分层，因此Isilon已将HDFS层作为一种适用于OneFS的网络协议集成。借助于该集成，用户可以将横向扩展NAS平台用作Hadoop核心组件以及任何生态系统组件的Hadoop体系结构的原生部分。（关于更多Isilon OneFS的介绍，请看参考中列出的几篇文档）

   

   另外，客户还能借此在整个Hadoop工作流中充分利用OneFS的简单性、灵活性、可靠性和效率。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIWIXXeFnNQKpHCIhPa98nHNp5oPEohG0SH0gww0JhACbRhTBWWWmpCiab5EdBZ9TPTlTmpfcXqR5Kg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

   上图显示了在通过网络协议（HDFS）将Isilon横向扩展NAS集成到Hadoop计算群集时的体系结构。这使得Isilon横向扩展NAS可以成为企业Hadoop工作流中的一等Hadoop公民。它还允许将Hadoop工作流的以下两个核心组件分开：计算层（MapReduce层）以及Hadoop分布式文件系统（HDFS，或存储层）。由于目前可用的网络带宽已经显著提高，而且OneFS在构建时在其核心使用了分布式并行的概念，因此企业客户可以在其使用Hadoop的数据分析工作流中利用共享的横向扩展存储模型。



   下面一张图是深入显示了与Isilon横向扩展NAS协同工作的Hadoop的所有核心组件以及生态系统组件。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIWIXXeFnNQKpHCIhPa98nHNufbIQlMichiaOZRyHYlMibTP2thQJbNVzr346e49q5PibMZtZfz8Yk0hpw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

   目前，EMC Isilon OneFS文件系统可以在单一文件系统和单一全局命名空间中扩展至15PB以上。在该容量下，它还可以扩展至85GB/s并发吞吐量。有关OneFS如何线性扩展至该容量以及Hadoop工作流性能要求的详细信息，请参阅specsfs2008基准测试结果（www.spec.org）



   后续文章中会介绍Hadoop工作流中利用EMC Isilon横向扩展NAS的重大优势。

















## EMC存储上的大数据 – HDFS on Isilon（二）

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-06*

 

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。



   本文为系列的第五篇，介绍HDFS与Isilon的集成简单的特点。

 

   EMC Isilon OneFS消除了与如下任务相关的复杂性：管理磁盘池；Isilon允许用户对阵列机架之上磁盘进行调配文件系统资源，这种做法相比管理大量Hadoop节点上的存储资源来的更加集中与简单。同时基于阵列的文件系统资源调配还能提供合适的数据保护机制。因此，企业的数据集随时可供访问并且受到充分的故障保护。OneFS让Hadoop变得更加简单易用，让企业可以专注于利用其数据来推导可加速业务发展的见解。这使得企业能够专注于使用Hadoop来发掘重要趋势，并且识别有助于加速业务发展的机会，而不是花费时间来管理其Hadoop生态系统的存储基础架构。



   扩展Isilon存储通常只需要不到60秒的时间，集群在线时只需按下按钮即可完成扩展。要将Isilon节点添加至现有集群，只需将其安装到机架上，开启电源，然后要求其加入现有的Isilon横向扩展集群。该“加入”过程可确保附加容量即刻刻用，而且在要加入的Isilon节点上运行的是正确的OneFS版本和配置。这样，不但可以在60秒钟内得到附加容量，而且还会运行一个后台作业，以在整个Isilon集群均匀地重新平衡当前利用率，从而避免数据热点。此容量扩展全部都是在横向扩展存储保持在线并且服务于MapReduce作业的情况下完成的，而且不会产生任何影响。



   除了支持HDFS协议以外，OneFS还支持NFS、CIFS\SMB、FTP、HTTP、iSCSI、REST等协议。Isilon HDFS实施是OneFS文件系统和HDFS客户端之间的一个轻量级协议层。这意味着文件存储在Isilon集群上的标准POSIX兼容文件系统中。如此，组织可真正地轻松利用上述任意协议，为其Hadoop工作流接受数据，或者将Hadoop得出的业务关键见解导出到数据分析工作流的其他组件。如果数据已经存储在EMC Isilon横向扩展NAS上，客户只要使其Hadoop计算环境指向OneFS，而不必为Hadoop工作流执行耗时耗资源的加载操作。OneFS使企业可以轻松地在其Hadoop环境中将HDFS层作为一个真正的、经过验证的文件系统使用。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIViaPoWDA046fyYlpCicu4f8BBK73W91qvtTwSaVWRbwaWttLBavBEdqickc1FMrcfF8VkgcibO6VbRvg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)















## EMC存储上的大数据 – HDFS on Isilon（三）

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-07*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。



   本文为系列的第六篇，介绍HDFS与Isilon的集成的效率与灵活性特点。

 

   Isilon的操作系统OneFS经过专门设计，可使横向扩展集群的容量利用率超过80%，从而大幅提升Hadoop数据分析工作的效率。与传统Hadoop体系的结构（通常对驻留在文件系统中的每个数据块使用3倍镜像）相比，OneFS具有极高的容量效率，可以为企业客户提供优化的ROI（投资回报率）和TCO（总拥有成本）。例如，如果企业想要存储12PB的Hadoop数据，则在默认使用3倍镜像来存储数据的传统Hadoop集群中，企业通常需要购买超过36PB的原始磁盘容量。然而，在使用OneFS的数据保护功能存储相同的12PB Hadoop数据时，只需要Isilon集群中具有15PB的原始磁盘容量。这会大大节约CAPEX（资本性支出），并且显著简化要管理的基础架构环境。



   除了Isilon为加大OPEX（企业的管理支出）节约幅度而带来的易于操作的简单管理以外，还可以在该环境中实现其他效率。例如，从容量角度而言，Isilon节点可以变得非常密集。因此，运行使用直连存储的36PB传统Hadoop集群所需的机架空间和电力可能大大超过支持相同数据需求的15PB Isilon集群。Isilon集群的这一优势会产生附加的成本节约效果。



   通过使用Isilon横向扩展NAS作为Hadoop环境的共享存储层，客户还可以聚合并最大程度地减少其Hadoop计算场。通过将所有与存储相关的HDFS开销加载到Isilon横向扩展NAS，可以更好地利用Hadoop计算场来执行更多的分析作业，而不是管理本地存储、保护其中的数据以及分析其中驻留的数据。通过将Hadoop计算场从执行上述所有HDFS相关人物的重负下解脱出来，OneFS可以帮助减少Hadoop计算场的占用空间，并且潜在地利用现有Hadoop计算基础架构来完成数据分析工作流中的其他任务。让共享存储可通过其他标准协议访问所带来的效率会让整个数据分析工作流获益匪浅，从而使Hadoop得出的重要简介更好地应用于数据分析工作流的其他部分。这种聚合存储方法有助于简化整个数据分析工作流，以便企业可以实现显著的CAPEX和OPEX节约效果。



   在使用直连存储的传统Hadoop集群中，计算层和存储层紧密耦合，因此用户无法仅扩展其中一个。这一特点导致的缺陷在于：客户将由于需要更多的存储容量（非计算容量）而扩展Hadoop集群。但是，在扩展过程中，客户现在会添加更多的网络基础架构和计算基础架构。从总体利用率而言，这被证明非常低效和不灵活。



   通过消除Hadoop计算层和存储层之间的耦合，企业将可在需要时灵活地单独扩展其中一层（存储）或另外一层（计算）。这种灵活的按需扩展体系结构使客户可以仅在需要的时候购买所需的产品，从而使整个复杂的Hadoop环境变得更加有效。借助于该功能，组织起初可以只构建一个小型体系结构，然后在需要时进行横向扩展，最高可在使用OneFS的Hadoop存储层上获得85GB/s的并发吞吐量。使用OneFS来满足Hadoop存储需求的一个重要优势是符合Apache Hadoop的要求，如此，组织即可灵活地选择理想的Hadoop版本，供Hadoop数据分析工作流使用。









## EMC存储上的大数据 – HDFS存储可靠性

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-08*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。本文为系列的第七篇，介绍传统HDFS数据存储与使用EMC Isilon在数据存储方面可靠性的对比。

 

   企业为了从其Hadoop分析投资中获取最大价值，企业需要富有弹性的大数据存储基础架构。在传统Hadoop集群中，用户必须依赖于自定义的子数据块CRC校验和来提供硬件层数据保护，并且在HDFS层使用镜像技术以保持某种级别的数据冗余。但是，在规模较大的情况下，这会成为一个非常高成本的方案。如果通过EMC Isilon作为存储层，Isilon的数据保护是在OneFS文件系统级别实施的，因此要使新的保护和性能方案可用，只需执行OneFS软件升级即可。OneFS使用经过广泛验证的Reed-Solomon擦除编码算法来执行其奇偶校验保护计算。在文件界别应用保护，使得集群可以快速高效地恢复数据。信息节点、目录和其他元数据在于其引用的数据块相同或更高的级别进行保护。由于所有数据、元数据和向前纠错（FEC）数据跨多个节点条带化，因此不需要专用的奇偶校验驱动器。这不仅可以防止出现单点故障和瓶颈，还使文件重建成为一个高度并行化的过程。



   OneFS还支持多种混合保护方案。这包括N+2：1和N+3：1，前者可针对两个驱动器故障或者一个节点故障提供保护，后者可针对三个驱动器故障或一个节点故障提供保护。对于高密度节点配置而言，这些保护方案特别有用。万一发生多个设备同时故障的情况，以至于文件“超过了其保护级别”，则OneFS将尽可能重新保护所有可保护的内容，并且将与受影响的个别文件相关的错误报告到Isilon集群的日志。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIXhxvDY2sMic7ApWsHq6lYJbbLgzj6ibRoqFgwzF1jPNlOy5Pt0FlHWNkz1ib7lyLhcwVTZ90bBP4Z7w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

Isilon还支持多项保证数据可靠性功能，例如：



- 日志文件系统：每个Isilon节点都配备了一个由双电池支持的NVRAM卡，以保护节点的文件系统。
- 主动节点/设备故障：OneFS将主动删除任何达到特点的已检测ECC错误阀值的驱动器，自动重建该驱动器中的数据并将其定位至该集群中的其他位置。整个过程完全自动化，无需人工干预。
- Isilon数据完整性：ISI数据完整性（IDI）是一种通过32位CRC校验和防止文件系统结构损坏的OneFS过程。所有Isilon数据块（包括文件和元数据）都利用校验和验证。
- 协议校验和：OneFS为远程数据块管理（RBM）协议数据提供了校验和验证。RBM是Isilon开发的机遇RPC的单播协议，可供在后端集群互连上使用。
- 动态扇区修复：DSR功能可用来隔离损坏的磁盘扇区，重新向完好的数据以便在其他位置重新写入。
- Mediascan：MediaScan在OneFS中的作用是检查磁盘扇区并部署DSR机制，以便强制磁盘驱动器修复他们可能遇到的任何扇区ECC错误。

 

总之，在HDFS存储层使用EMC Isilon存储，可以避免多种传统Hadoop存储实施的许多缺点，如下所示：

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIXhxvDY2sMic7ApWsHq6lYJbLG3JtgMwViaXTaCOBqthsNTvl7o5uQWZYGmUDbYrKJFfnABRrp2VyxQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)











## EMC存储上的大数据 – 基础架构与数据分析

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-11*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。



   本文为系列的第八篇，介绍了EMC满足企业大数据部署的基础架构与分析服务的系列产品。

 

   众所周知，在企业部署与利用大数据之旅中，企业若能发掘大数据来改善战略与执行能力，也就代表他们正在拉开与竞争者的优势距离。来自EMC的大数据产品可以从多方位的角度满足企业大数据部署与利用的各项需求，他们包括横向扩展存储，统一分析平台以及业务流程与应用程序开发工具。凭借这些工具，组织可以获得更深入的洞察力，跻身为预测能力更强大的组织。



EMC确定了简单的三个大数据之旅阶段：



- 大数据基础架构：构建于具有横向扩展存储和分析的大数据基础平台之上。
- 敏捷分析：让数据科学家能够以一种高效敏捷的协作方式分析大数据。
- 可行性洞察：让大数据分析嵌入应用程序中，以跻身为预测型组织。



   第一阶段大数据基础架构讲述由横向扩展存储和云存储以及分析平台组成的大数据基础架构技术。大数据存储，要实现大数据规模，组织需要一种横向扩展的自动化存储平台，借此以最低的额外运营成本增加容量，并实现可扩展性、性能和吞吐量。



- EMC Isilon这种横向扩展平台可以提供理想的大数据存储。在OneFS操作系统的支持下，Isilon节点汇聚成一种高性能的单一存储池。随着大数据量的增加，只需要花几分钟即可增加容量，还能获得线性性能提升。经证明，Isilon对存储的利用率高达80%，IOPS更是高达数百万，它提供的扩展能力和性能可充分满足大数据需求。
- EMC Atmos大数据云存储针对不管是内容和服务提供商，还是需要分布式大数据的全球企业，EMC Atmos都是理想的选择。EMC Atmos提供多PB级云存储，运用自动化策略推进数据生命周期，借助安全的多租户功能简化资源调配，并提供任意设备自助访问，从而实现全球规模的大数据管理。



   大数据分析，要获得大数据洞察力，需要一种将结构化和非结构化与实时供给和查询相集成的分析平台，EMC大数据平台有Pivotal Greenplum Database和Pivotal HD组成：



- Pivotal Greenplum Database是一种大规模并行处理（MPP）数据库，它可管理、存储和分析PB级的结构化数据。这种数据库的部署需使用由企业级服务器、存储和以太网交换机组成的横向扩展集群。借助集群中所有节点的计算能力，它可以快速加载数据（高达10TB/小时）和处理查询。
- Pivotal HD是一种经过开放源代码认证并且受支持的Apache Hadoop堆栈，您可以借此将非结构化数据转换为结构化数据，从而协同处理Pivotal Greenplum Database中的数据。
- Pivotal和Isilon Hadoop集成解决方案，组织可以使用企业Hadoop解决方案部署基于Apache的Hadoop大数据分析。这种解决方案包含EMC Isilon以及本机HDFS和Pivotal HD，也因此开放源代码逐渐和硬件实现轻松而简单的集成。EMC提供了一种企业级综合解决方案，以在灵活且高度可扩展的高效存储平台上实现强大的大数据分析。











## EMC存储上的大数据 – 敏捷分析与可行性洞察

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-12*

  企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。



  本文为系列的第九篇，介绍了EMC满足企业大数据实现敏捷分析与可行性洞察系列产品。



   众所周知，在企业部署与利用大数据之旅中，企业若能发掘大数据来改善战略与执行能力，也就代表他们正在拉开与竞争者的优势距离。来自EMC的大数据产品可以从多方位的角度满足企业大数据部署与利用的各项需求，他们包括横向扩展存储，统一分析平台以及业务流程与应用程序开发工具。凭借这些工具，组织可以获得更深入的洞察力，跻身为预测能力更强大的组织。



EMC确定了简单的三个大数据之旅阶段：

- 大数据基础架构：构建于具有横向扩展存储和分析的大数据基础平台之上。
- 敏捷分析：让数据科学家能够以一种高效敏捷的协作方式分析大数据。
- 可行性洞察：让大数据分析嵌入应用程序中，以跻身为预测型组织。



   第二阶段敏捷分析，随着大数据分析的剧增，一种全新的角色悄然升起 – 数据科学家。数据科学家负责分析和解释数据集，帮助组织获得更深入的洞察力以及竞争力的优势。大数据之旅的第二季端重点讲述如何向组织人员（包括数据科学家团队）授权一级如何开发一套让他们实现更高效率、更敏捷和更密切协作的流程。



**Pivotal CHORUS：大数据社会化**

  

   Pivotal Chorus为数据科学家团队提供了敏捷分析和开放环境。Chorus分析生产效率平台集自助服务、内置协作和社交网络功能于一身，数据科学家团队可借此访问和分析相关数据集，调配沙盒环境，跟踪代码更改以及与其他团队实时共享信息。



**Pivotal UAP：统一和加速敏捷分析**



   Pivotal Greenplum Database、Pivotal HD和Pivotal Chorus打包为Unified Analytics Platform（UAP），可进一步加速敏捷分析之旅。通过部署这种统一方法，整个组织都能借助单一平台中的协同处理和协作功能来转变数据使用方式。



   大数据之旅的第三阶段重点介绍如何通过在所有决策流程中运用环境数据，跻身为预测型企业。因此企业将能洞察未来的结果，跻身为预测能力更为强大的组织。



   EMC DOCUMENTUM XCP使用数据和分析来触发应用程序中的工作流和业务流程。xCP获取数据和内容丰富的协作式交互，并将其整合到一套具有清晰的角色、后续步骤及结果的结构化流程之中。



   Pivotal LAB提供灵活的软件开发、咨询服务和工具，帮助组织开发构建与Pivotal UAP之上的大数据应用程序。

最后，凭借EMC强而有力的大数据支持，用户将获得一种横向扩展的基础架构、它运用统一分析平台，业务流程和应用程序开发工具将大数据嵌入到应用程序之中。有了这些技术，再加上EMC咨询服务，用户将能开启“大数据”的价值宝库，使效率、敏捷性和业务突破达到更高水平。















## EMC存储上的大数据 – 大数据分析实施路线

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-13*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。本文为系列的第十篇，介绍了发现适当的大数据业务机会并制定利用该机会的全面路线图。

 

   大数据时代，各公司都在努力挖掘有关他们业务的令人信服的见解，以赢得竞争优势。他们在探索具有独特见解的问题，例如：谁是我最有价值的客户？哪些是我最重要的产品？什么是我最成功的营销活动？



   过去，IT和企业用户只能使用可用企业信息中的一小部分来尝试回答这些重要问题。因此，行业调查记录了这样一些事实，企业领导者们：

- 常常在不具备他们所需信息的情况下制定重要决策。
- 根据自觉和经验而不是根据可靠核实的信息制定重要业务决策
- 意识到组织中的管理者因为无法获取准确的信息而制定了错误的决策
- 无法再组织范围内获得履行其职责所需的信息



   大量类型复杂的新数据（即“大数据”）现在已可用并且随时可供访问，同时还可提供有关客户、产品和运营的创新见解。这些新的数据源（Web活动、移动或位置数据以及社交信息）再加上传统数据源，提供了达到当前无法实现的业务洞察水平的机会。借助这些新的数据源，企业用户不再局限于仅通过财务指标来衡量成功是否，而是可以考虑客户、产品和营销活动对业务的整体贡献，从而超越其业界同行。

  

   而整个过程中，需要制定大数据战略以利用这些新的业务见解，就意味着企业不能只考虑数据量。一个成功的大数据战略必须考虑获得信息的速度、信息的多样性和复杂性：

- 数量：数据量达到若干PB
- 速度：实时生成的接受信息进行分析
- 多样性：表格、文档、电子邮件、计量、网络、视频、图像和音频
- 复杂性：每种类型数据都有不同的标注、领域规则和存储格式



   企业需要发现适当的打虎踞机会并制定全面的路线图来利用该机会。通过分布式的方法确保大数据管理和体系结构能够解决因种类繁多的数据格式、获得数据的速度以及信息资产的复杂性而产生的问题。许多现有的工具、平台和方法都可能需要升级才能够发挥大数据的业务潜力。



**步骤1：选择最适合的优先业务机会。**

  

   确定大数据实施路线的第一步是确定大数据和分析可以在哪方面以及如何支持组织。通过经验和分析评估的方法来确定具有以下特点的战略性业务计划：

- 跨职能部门
- 提供有吸引力的业务价值
- 具有可衡量的目标
- 具有明确规定的交付期限

 

**步骤2：构建驱动下一代业务职能和分析的使用情形**



   需要有涵盖报告、控制面板、临时查询和分析全面用户体验，以支持通过大数据实现的更及时的决策制定。可以考虑利用一下情形和方法，确定新的大数据源对企业BI和分析系统的影响：

- 评估当前BI和分析环境
- 记录大数据对BI和分析环境的影响
- 将当前功能映射到大数据的实施曲线

 

**步骤3：为更灵活的数据平台创建概念性体系结构**



   以OLTP为中心的传统关系数据库管理系统从未针对大数据进行设计。传统的数据管道无法满足大数据分析的需求。快速增长的数据量将传统数据管道推向了面临崩溃的边缘，迫使组织使用数据的摘要和样本。结果就是从数据到分析的周期时间长达数周，而不是几个小时，因此分析的质量也受到影响。基于大规模并行处理（MPP）的新数据仓库提供可扩展、灵活的数据仓库平台，能够挖掘结构化和非结构化大数据的业务价值。企业需要制定计划，以支持快速接收新的结构化和非结构化大数据源，包括：

- 评估当前的数据仓库黄金并记录大数据对它的影响
- 评估当前的ETL并记录大数据对它的影响
- 创建灵活的数据仓库体系结构

 

**步骤4：评估数据质量、管理和安全措施的可用性**



   待分析的数据必须能够提供您业务的可靠视图。组织需要一个将数据视为一种资产而不是一项开支的“业务计划“。此数据业务计划必须涵盖数据质量、治理和安全措施，并同时开拓内部数据以及第三方数据源。一个全面的、设计合理的计划在运营过程中将会持续不断地监控、增强和确保组织的战略数据存储的安全性、准确性和完整性，并制定数据规程、政策和组织纪律。

 

**步骤5：制定应用云功能的愿景**



   云体系结构可能会影响企业信息管理功能。它为自助式BI和分析提供了机会。它可以为围绕特定主题领域或业务机会进行的分析提供集成式协作。如果使用得当，它可以快速实现“数据化货币”。为了帮助利用云体系结构实现数据管理功能的转型，企业需要：

- 针对面临的大数据挑战审核云功能和实现方法
- 将您当前的功能映射到云架构
- 确定云可能会产生实质影响的特定体系结构和运营领域，并记录有关数据仓库体系结构和操作、报告和业务职能及用户体验、高级分析部署、数据质量管理等云数据部署建议。

 

**步骤6：将查询结构整合到阶段是路线图中。**



   企业针对的大数据实施构建一个全面的转型路线图，重点为以划分优先级的关键业务提供支持，该路线图许针对组织特有的技术要求以及功能量身定制。

















## EMC存储上的大数据–软件定义存储模型

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-14*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。



   本文为系列的第十一篇，介绍了EMC ViPR针对的大数据环境的存储模型与体系结构。

 



**软件定义的存储模型:**

 

   EMC ViPR是存储虚拟化软件平台，它将物理阵列中的存储（无论是基于文件、块还是对象）抽象为虚拟共享存储资源池，从而跨物理阵列实现灵活的存储使用模型，并提供应用程序和创新型数据服务。ViPR从底层硬件阵列抽象出存储控制路径，以便可以在软件中集中执行多供应商存储基础架构的访问和管理。如下图：



![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIUicAbR0urp5dicPiaZbicAjvOmE1ibR9oicGM2LDIzpFGGQWrE5su8xtDDlZ7kCjZSvb0hPJOwaqpp2GOw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

总体而言，ViPR的软件定义存储模型的特点有三个：



1. ViPR所实现的将存储路径与数据路径分开，通过抽象出控制路径，存储管理将在虚拟层执行，使得用户能够将其存储池划分为许多虚拟存储阵列。并由策略以独有的方式管理他们，这方式类似于将服务器划分为多个虚拟机。但是，ViPR会干预文件和块存储的数据路径。控制路径与数据路径的这种分离，不仅让ViPR能够集中执行所有数据调配和数据管理任务，而且允许应用程序访问数据和块数据，因为他们始终必须继续使用存储阵列中嵌入的独特数据服务。
2. ViPR还提供块和文件控制服务，这些服务将物理块和文件存储阵列的所有功能作为虚拟服务进行提供。通过控制服务，用户可管理块卷，文件系统的高级保护服务，例如快照、克隆和复制。相比公有云中的虚拟存储，ViPR可以不需要放弃那些存储阵列的高级功能，同时对存储进行虚拟化。
3. ViPR还提供了更多扩展，管理员和开发人员可以创建跨阵列的数据服务。例如，开发人员创建对象存储在文件服务器上运行，并利用文件服务器的性能。并且让对象存储和文件服务器同时通过数据路径被访问，再例如，组织可以在高性能的NAS设备上存储、访问和操作对象，而不必重写现有基于文件的应用程序。开发人员可以在软件中一次创建新的阵列功能，然后再任何阵列中运行，也不必执行重写。





**ViPR体系结构：**

 

   ViPR使用多供应商存储环境看起来就像一个大的虚拟阵列。ViPR使用链接到底层阵列的软件适配器，这类似于设备驱动程序通过设备与PC兼容所采用的方式。ViPR提供了开放式的API，因此，任何供应商、合作伙伴和客户都可以构建新的适配器以添加新阵列。这创建了可扩展的“即插即用”存储环境，从而可以自动连接，发现和映射阵列、主机和SAN结构。



![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIUicAbR0urp5dicPiaZbicAjvOmMiciaK3NZINicRdvf7CCCrwcAaDEZ2QG28T8lmnoeF4dorQynKOLJZy7g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

   ViPR隐藏了所有底层存储阵列的复杂性，并展示了其作为数据服务的核心功能，同时还保留了阵列的特有属性。存储管理员然后可以在ViPR中创建代表特有应用程序工作负载所需的功能集和虚拟存储池。例如，数据有高性能块存储特征的虚拟存储池来适合事务性工作负载。诸如在线文件和内容共享等云应用程序对性能不敏感，在能够更经济地提供必要的数据保护和可用性级别的普通廉价硬盘上就能运行的很好。或者针对大数据分析环境，对使用对象和文件数据服务的密集型应用程序，利用混合文件与对象，利用高性能的NAS作为存储。对于上述任意一种情况，用户都可以根据其工作负载需求订购虚拟存储池。用户不需要了解或关心将为其应用程序提供数据服务的底层硬件和软件的具体信息。这都得益于ViPR不是在特定阵列中调配空间，而是让存储管理员能够提供独特的，可自定义的硬件和软件资源组合作为可使用的数据服务。















## EMC存储上的大数据 – 软件定义存储数据服务与HDFS

原创 EMC中文技术社区 [戴尔易安信技术支持](javascript:void(0);) *2016-07-15*

   企业一直在处理快速增长的数据量（也称为大数据）的存储和管理问题。



   本文为系列的第十二篇，介绍了EMC ViPR针对HDFS的数据服务。

 

**ViPR全局数据服务:**

 

   ViPR全局数据服务允许管理员和开发人员开发跨阵列并支持混合数据类型的新全球数据服务。全局数据服务属于存储抽象化，反映数据类型（文件、对象、数据块和混合数据类型）、访问协议（iSCSI、NFS、REST等）以及持久性、可用性和安全性特征（快照、复制等）的组合。ViPR全局数据服务示例包括：



**文件中对象数据服务：**



   EMC ViPR文件中对象数据服务提供了将非结构化数据（例如，图像、视频、音频、联机文档）作为基于文件中对象的存储（例如EMC VNX、Isilon和NetApp存储系统）进行存储、访问和操作，而不必重写或重新处理现有基于文件的应用程序。ViPR文件中对象数据服务是在不同硬件平台上透明运行的软件层。最初，ViPR文件中对象数据服务为用户提供了使用Amazon S3、OpenStack Swift和EMC Atmos API管理对象数据以及访问文件系统上的数据的功能。ViPR文件中对象数据服务提供对文件阵列的直接路径访问。特别是，由于企业写入到文件系统的现有应用程序不必重新编码即可利用ViPR，因此他们可以从此功能受益。



**HDFS数据服务：**



   ViPR作为支持HDFS的优秀平台之一，它可以让组织利用现有的数据存储阵列（例如VNX，Isilon和NetApp）在主流的Hadoop发行上运行大数据分析。基于Hadoop以及成为现阶段企业在大数据之旅上的主要研究与部署对象，且HDFS是Hadoop的核心分布式文件系统，许多企业在实验室中都拥有HDFS项目。然而，许多企业发现Hadoop在部署和扩展上很困难。而ViPR则可以帮助组织利用现有的存储来解决这种困难，而且这种解决方案是被EMC所验证的。相比部署只针对大数据分析的专有存储架构，利用位于已有存储资源的虚拟化ViPR HDFS数据服务，无论是在资源利用率和管理性上都拥有明显的优势。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIUicAbR0urp5dicPiaZbicAjvOmlqKia3vBEicE9ug8by3Oe7NoCSf2qzZHHBMAYLlabnRLvCoK9cIQjcmA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

   鉴于Hadoop的发展趋势，灵活的软件模型在未来允许计算与存储分离。ViPR也将在未来支持专用的硬件设备，在这种情况下，ViPR可以更好的充当Hadoop的企业级存储子系统。ViPR同时拥有基于地域复制的灾难恢复功能。而且，ViPR还支持将Hadoop分布式文件系统（HDFS）支持将对使用对象和文件数据服务的数据密集型应用程序应用位置感知。处理工作在数据所在的执行器节点上执行，而不必再遍历网络，从而减少了主干网络的流量。

 

![图片](http://mmbiz.qpic.cn/mmbiz/TztEwAzAQIUicAbR0urp5dicPiaZbicAjvOmcqG0nsDxHoqyuibJZxbmJCcNXabJtF5GFzXQ39N88JxMeibNP8CA87fw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 

总结来说，ViPR的优势有：

- 解决需要部署专用Hadoop专用存储的局限性
- 允许HDFS运行在已有的存储硬件之上
- 支持HDFS/对象/文件不同的存储方式
- 灵活的软件模型



















